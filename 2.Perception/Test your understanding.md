# Questions

1. What is the role of perception in autonomous systems?a)	To plan the motion of the carb)	To detect and understand the environmentc)	To control the car's steeringd)	To interpret human speechAnswer: b) To detect and understand the environment
2. Which of the following is NOT an example of perception in an autonomous car?a)	Detecting drivable spaceb)	Knowing where lanes arec)	Identifying other vehiclesd)	Calculating fuel efficiencyAnswer: d) Calculating fuel efficiency
3. What is perception mainly concerned with in autonomous systems?a)	Navigationb)	Communicationc)	Sensing the environment and objectsd)	User interactionAnswer: c) Sensing the environment and objects
4. Perception helps autonomous systems understand...a)	User preferencesb)	Surrounding objects and their positionsc)	Weather conditionsd)	Voice commandsAnswer: b) Surrounding objects and their positions
5. Which of these is an example of a static object in the perception system of an autonomous car?a)	Pedestriansb)	Vehiclesc)	Curbsd)	AnimalsAnswer: c) Curbs
6. The primary purpose of detecting curbs in an autonomous car is to...a)	Identify pedestrian pathwaysb)	Determine road boundariesc)	Track other vehiclesd)	Measure the width of the roadAnswer: b) Determine road boundaries
7. What is a common sensor used for perception in autonomous vehicles?a)	Microphoneb)	LIDARc)	Speakerd)	RadarAnswer: b) LIDAR
8. Perception helps autonomous systems in detecting...a)	Traffic signsb)	Engine statusc)	Internal temperatured)	Battery lifeAnswer: a) Traffic signs
9. Which of these sensors is typically used to detect the presence of nearby vehicles?a)	GPSb)	Camerac)	LIDARd)	ThermometerAnswer: c) LIDAR
10. Perception allows an autonomous car to understand traffic lights for...a)	Speed adjustmentb)	Directional guidancec)	Decision makingd)	GPS navigationAnswer: c) Decision making
     
11. Detecting pedestrians is an example of which type of perception?a)	Static object detectionb)	Dynamic object detectionc)	Terrain classificationd)	Lane detectionAnswer: b) Dynamic object detection
12. Computer vision is a technique used in perception to...a)	Control the car’s engineb)	Analyze images from sensorsc)	Interpret GPS datad)	Process speechAnswer: b) Analyze images from sensors
13. Which of the following is NOT a goal of perception in autonomous cars?a)	Detecting pedestriansb)	Measuring air qualityc)	Understanding traffic signsd)	Identifying other vehiclesAnswer: b) Measuring air quality
14. Autonomous cars use perception to...a)	Predict the weatherb)	Detect static and dynamic objectsc)	Communicate with other vehiclesd)	Provide entertainment to passengersAnswer: b) Detect static and dynamic objects
15. Traffic lights are considered...a)	Dynamic objectsb)	Static objectsc)	Moving objectsd)	Virtual objectsAnswer: b) Static objects
     
16. Perception can help detect drivable space. This is crucial for...a)	Predicting trafficb)	Vehicle navigationc)	Analyzing weatherd)	Reducing speedAnswer: b) Vehicle navigation
17. A vehicle using perception can recognize pedestrians through...a)	Audio signalsb)	Computer visionc)	GPS trackingd)	Traffic reportsAnswer: b) Computer vision
18. Which of these elements is classified as a dynamic object?a)	Traffic lightb)	Vehiclec)	Curbd)	Lane markingAnswer: b) Vehicle
19. Perception systems in autonomous vehicles often rely on...a)	LIDAR and camerasb)	GPS and radio signalsc)	Wi-Fi and cellular datad)	Radar and heat sensorsAnswer: a) LIDAR and cameras
20. LIDAR is primarily used for...a)	Calculating distancesb)	Speech recognitionc)	Weather predictiond)	Route planningAnswer: a) Calculating distances 
21. Perception helps in detecting the location of...a)	Speed limitsb)	Lanes and curbsc)	Weather changesd)	Fuel levelsAnswer: b) Lanes and curbs
22. In an autonomous system, knowing the location of other vehicles is important for...a)	Reducing emissionsb)	Preventing collisionsc)	Measuring fuel efficiencyd)	Route optimizationAnswer: b) Preventing collisions
23. Perception technology in autonomous cars can help identify which of the following?a)	Pedestriansb)	Internal battery statusc)	Tire pressured)	Fuel qualityAnswer: a) Pedestrians
24. Cameras in perception systems are primarily used for...a)	Detecting objectsb)	Engine diagnosticsc)	Communicationd)	Tracking GPSAnswer: a) Detecting objects
25. Understanding traffic signs is important in perception because it helps the vehicle...a)	Maintain speed
    b)	Decide when to stop or goc)	Communicate with other vehiclesd)	Navigate curvesAnswer: b) Decide when to stop or go
     
26. Which sensor is known for providing high-resolution images for object recognition in autonomous vehicles?
    a)	LIDAR
    b)	Camera
    c)	Radar
    d)	IMU
    Answer: b) Camera
27. What does YOLO stand for in the context of object detection?
    a)	You Only Look Once
    b)	 Yield Over Light Object
    c)	 You Observe Light Objects
    d)	 Yield Obstacle Line Object
    Answer: a) You Only Look Once
28. Which of the following is a challenge for perception in autonomous vehicles?
    a)	Low computing power
    b)	Sensor uncertainty and occlusion
    c)	Excessive battery consumption
    d)	Limited sensor types
    Answer: b) Sensor uncertainty and occlusion
29. In computer vision, what is the purpose of edge detection?
    a)	To recognize objects in an image
    b)	To find the boundaries of objects within an image
    c)	To classify features into different categories
    d)	enhance image contrast
    Answer: b) To find the boundaries of objects within an image
30. What is the advantage of using a convolutional layer in deep learning for image processing?
    a)	Reduces the complexity of data
    b)	Reduces the number of parameters compared to fully connected layers
    c)	Provides better accuracy for all image resolutions
    d)	Reduces the need for large datasets
    Answer: b) Reduces the number of parameters compared to fully connected layers
     
31. Which machine learning step involves adjusting parameters to minimize error during training?
    a)	Feature extraction
    b)	Hyperparameter tuning
    c)	Gradient descent
    d)	Image preprocessing
    Answer: c) Gradient descent
32. In which type of image are pixel values limited to black and white?
    a)	Grayscale image
    b)	Color image
    c)	Binary image
    d)	Infrared image
    Answer: c) Binary image
33. Which of the following sensors works by sending beams of light to measure distance?
    a)	Camera
    b)	RADAR
    c)	LIDAR
    d)	Ultrasonic sensor
    Answer: c) LIDAR
34. Which of the following is an essential part of the computer vision pipeline?
    a)	Depth estimation
    b)	Path planning
    c)	Feature extraction
    d)	Data fusion
    Answer: c) Feature extraction
35. Which of the following is an issue when using cameras in adverse weather conditions?
    a)	Overheating
    b)	Signal reflection
    c)	Low resolution
    d)	Poor image quality due to rain or fog
    Answer: d) Poor image quality due to rain or fog
     
36. Which feature of a sensor enables the detection of motion and changes in velocity?
    a)	Ultrasonic sensor
    b)	IMU (Inertial Measurement Unit)
    c)	LIDAR
    d)	Stereo camera
    Answer: b) IMU (Inertial Measurement Unit)
37. What is the primary function of the feature detection step in the computer vision pipeline?
    a)	To classify objects
    b)	To preprocess images
    c)	To identify important points of interest in an image
    d)	To measure depth in an image
    Answer: c) To identify important points of interest in an image
38. What is the key advantage of using stereo cameras in autonomous vehicles?
    a)	Detecting speed
    b)	Cost-effectiveness
    c)	Depth estimation
    d)	High resolution in low-light conditions
    Answer: c) Depth estimation
39. Which component of a digital image represents the smallest unit of brightness and color?
    a)	Pixel
    b)	Frame
    c)	Histogram
    d)	Filter
    Answer: a) Pixel
40. Which step in the computer vision pipeline is used to improve image contrast and detail?
    a)	Thresholding
    b)	Histogram equalization
    c)	Noise removal
    d)	Feature extraction
    Answer: b) Histogram equalization
41. What is the main advantage of using a convolutional neural network (CNN) in perception tasks?
    a)	It can process high-dimensional data efficiently
    b)	It requires no training
    c)	It is a low-cost solution
    d)	It uses fewer sensors
    Answer: a) It can process high-dimensional data efficiently
42. What is the primary difference between a grayscale image and a color image?
    a)	Grayscale images use more pixels than color images
    b)	Grayscale images store brightness values, while color images store RGB values
    c)	Grayscale images are harder to process
    d)	Color images only have two brightness values
    Answer: b) Grayscale images store brightness values, while color images store RGB values
43. Which type of image is most simple to process and analyze in computer vision?
    a)	Grayscale image
    b)	Color image
    c)	Binary image
    d)	Depth image
    Answer: c) Binary image
44. What is the purpose of the cost function in a machine learning model?
    a)	To measure how well the model fits the data
    b)	To calculate the total processing power needed
    c)	To determine the accuracy of object detection
    d)	To train the model for image preprocessing
    Answer: a) To measure how well the model fits the data
