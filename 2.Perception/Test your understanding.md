# Questions

1. What is the role of perception in autonomous systems?

   a) To plan the motion of the car

   b) To detect and understand the environment

   c) To control the car's steering

   d) To interpret human speech

   **Answer** : b) To detect and understand the environment

1. Which of the following is NOT an example of perception in an autonomous car?

   a) Detecting drivable space

   b) Knowing where lanes are

   c) Identifying other vehicles

   d) Calculating fuel efficiency

   **Answer** : d) Calculating fuel efficiency

1. What is perception mainly concerned with in autonomous systems?
   
   a) Navigation
   
   b) Communication
   
   c) Sensing the environment and objects
   
   d) User interaction
   
   **Answer** : c) Sensing the environment and objects

1. Perception helps autonomous systems understand...
   
   a) User preferences
   
   b) Surrounding objects and their positions
   
   c) Weather conditions
   
   d) Voice commands
   
   **Answer** : b) Surrounding objects and their positions
1. Which of these is an example of a static object in the perception system of an autonomous car?
   a) Pedestrians
   b) Vehicles
   c) Curbs
   d) Animals
   **Answer** : c) Curbs
1. The primary purpose of detecting curbs in an autonomous car is to...
   a) Identify pedestrian pathways
   b) Determine road boundaries
   c) Track other vehicles
   d) Measure the width of the road
   **Answer** : b) Determine road boundaries
1. What is a common sensor used for perception in autonomous vehicles?
   a) Microphone
   b) LIDAR
   c) Speaker
   d) Radar
   **Answer** : b) LIDAR
1. Perception helps autonomous systems in detecting...
   a) Traffic signs
   b) Engine status
   c) Internal temperature
   d) Battery life
   **Answer** : a) Traffic signs
1. Which of these sensors is typically used to detect the presence of nearby vehicles?
   a) GPS
   b) Camera
   c) LIDAR
   d) Thermometer
   **Answer** : c) LIDAR
1. Perception allows an autonomous car to understand traffic lights for...
   a) Speed adjustment
   b) Directional guidance
   c) Decision making
   d) GPS navigation
   **Answer** : c) Decision making
1. Detecting pedestrians is an example of which type of perception?
   a) Static object detection
   b) Dynamic object detection
   c) Terrain classification
   d) Lane detection
   **Answer** : b) Dynamic object detection
1. Computer vision is a technique used in perception to...
   a) Control the car’s engine
   b) Analyze images from sensors
   c) Interpret GPS data
   d) Process speech
   **Answer** : b) Analyze images from sensors
1. Which of the following is NOT a goal of perception in autonomous cars?
   a) Detecting pedestrians
   b) Measuring air quality
   c) Understanding traffic signs
   d) Identifying other vehicles
   **Answer** : b) Measuring air quality
1. Autonomous cars use perception to...
   a) Predict the weather
   b) Detect static and dynamic objects
   c) Communicate with other vehicles
   d) Provide entertainment to passengers
   **Answer** : b) Detect static and dynamic objects
1. Traffic lights are considered...
   a) Dynamic objects
   b) Static objects
   c) Moving objects
   d) Virtual objects
   **Answer** : b) Static objects
1. Perception can help detect drivable space. This is crucial for...
   a) Predicting traffic
   b) Vehicle navigation
   c) Analyzing weather
   d) Reducing speed
   **Answer** : b) Vehicle navigation
1. A vehicle using perception can recognize pedestrians through...
   a) Audio signals
   b) Computer vision
   c) GPS tracking
   d) Traffic reports
   **Answer** : b) Computer vision
1. Which of these elements is classified as a dynamic object?
   a) Traffic light
   b) Vehicle
   c) Curb
   d) Lane marking
   **Answer** : b) Vehicle
1. Perception systems in autonomous vehicles often rely on...
   a) LIDAR and cameras
   b) GPS and radio signals
   c) Wi-Fi and cellular data
   d) Radar and heat sensors
   **Answer** : a) LIDAR and cameras
1. LIDAR is primarily used for...
   a) Calculating distances
   b) Speech recognition
   c) Weather prediction
   d) Route planning
   **Answer** : a) Calculating distances
1. Perception helps in detecting the location of...
   a) Speed limits
   b) Lanes and curbs
   c) Weather changes
   d) Fuel levels
   **Answer** : b) Lanes and curbs
1. In an autonomous system, knowing the location of other vehicles is important for...
   a) Reducing emissions
   b) Preventing collisions
   c) Measuring fuel efficiency
   d) Route optimization
   **Answer** : b) Preventing collisions
1. Perception technology in autonomous cars can help identify which of the following?
   a) Pedestrians
   b) Internal battery status
   c) Tire pressure
   d) Fuel quality
   **Answer** : a) Pedestrians
1. Cameras in perception systems are primarily used for...
   a) Detecting objects
   b) Engine diagnostics
   c) Communication
   d) Tracking GPS
   **Answer** : a) Detecting objects
1. Understanding traffic signs is important in perception because it helps the vehicle...
   a) Maintain speed
   b) Decide when to stop or go
   c) Communicate with other vehicles
   d) Navigate curves
   **Answer** : b) Decide when to stop or go
1. Which sensor is known for providing high-resolution images for object recognition in autonomous vehicles?
   a) LIDAR
   b) Camera
   c) Radar
   d) IMU
   **Answer** : b) Camera
1. What does YOLO stand for in the context of object detection?
   a) You Only Look Once
   b) Yield Over Light Object
   c) You Observe Light Objects
   d) Yield Obstacle Line Object
   **Answer** : a) You Only Look Once
1. Which of the following is a challenge for perception in autonomous vehicles?
   a) Low computing power
   b) Sensor uncertainty and occlusion
   c) Excessive battery consumption
   d) Limited sensor types
   **Answer** : b) Sensor uncertainty and occlusion
1. In computer vision, what is the purpose of edge detection?
   a) To recognize objects in an image
   b) To find the boundaries of objects within an image
   c) To classify features into different categories
   d) Enhance image contrast
   **Answer** : b) To find the boundaries of objects within an image
1. What is the advantage of using a convolutional layer in deep learning for image processing?
   a) Reduces the complexity of data
   b) Reduces the number of parameters compared to fully connected layers
   c) Provides better accuracy for all image resolutions
   d) Reduces the need for large datasets
   **Answer** : b) Reduces the number of parameters compared to fully connected layers



1. Which machine learning step involves adjusting parameters to minimize error during training?
   a)	Feature extraction
   b)	Hyperparameter tuning
   c)	Gradient descent
   d)	Image preprocessing
   Answer: c) Gradient descent
4. In which type of image are pixel values limited to black and white?
   a)	Grayscale image
   b)	Color image
   c)	Binary image
   d)	Infrared image
   Answer: c) Binary image
5. Which of the following sensors works by sending beams of light to measure distance?
   a)	Camera
   b)	RADAR
   c)	LIDAR
   d)	Ultrasonic sensor
   Answer: c) LIDAR
6. Which of the following is an essential part of the computer vision pipeline?
   a)	Depth estimation
   b)	Path planning
   c)	Feature extraction
   d)	Data fusion
   Answer: c) Feature extraction
7. Which of the following is an issue when using cameras in adverse weather conditions?
   a)	Overheating
   b)	Signal reflection
   c)	Low resolution
   d)	Poor image quality due to rain or fog
   Answer: d) Poor image quality due to rain or fog
    
8. Which feature of a sensor enables the detection of motion and changes in velocity?
   a)	Ultrasonic sensor
   b)	IMU (Inertial Measurement Unit)
   c)	LIDAR
   d)	Stereo camera
   Answer: b) IMU (Inertial Measurement Unit)
9. What is the primary function of the feature detection step in the computer vision pipeline?
   a)	To classify objects
   b)	To preprocess images
   c)	To identify important points of interest in an image
   d)	To measure depth in an image
   Answer: c) To identify important points of interest in an image
10. What is the key advantage of using stereo cameras in autonomous vehicles?
    a)	Detecting speed
    b)	Cost-effectiveness
    c)	Depth estimation
    d)	High resolution in low-light conditions
    Answer: c) Depth estimation
11. Which component of a digital image represents the smallest unit of brightness and color?
    a)	Pixel
    b)	Frame
    c)	Histogram
    d)	Filter
    Answer: a) Pixel
12. Which step in the computer vision pipeline is used to improve image contrast and detail?
    a)	Thresholding
    b)	Histogram equalization
    c)	Noise removal
    d)	Feature extraction
    Answer: b) Histogram equalization
13. What is the main advantage of using a convolutional neural network (CNN) in perception tasks?
    a)	It can process high-dimensional data efficiently
    b)	It requires no training
    c)	It is a low-cost solution
    d)	It uses fewer sensors
    Answer: a) It can process high-dimensional data efficiently
14. What is the primary difference between a grayscale image and a color image?
    a)	Grayscale images use more pixels than color images
    b)	Grayscale images store brightness values, while color images store RGB values
    c)	Grayscale images are harder to process
    d)	Color images only have two brightness values
    Answer: b) Grayscale images store brightness values, while color images store RGB values
15. Which type of image is most simple to process and analyze in computer vision?
    a)	Grayscale image
    b)	Color image
    c)	Binary image
    d)	Depth image
    Answer: c) Binary image
16. What is the purpose of the cost function in a machine learning model?

    To measure how well the model fits the data
    b)	To calculate the total processing power needed
    c)	To determine the accuracy of object detection
    d)	To train the model for image preprocessing
    Answer: a) To measure how well the model fits the data
